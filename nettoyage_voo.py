# -*- coding: utf-8 -*-
"""Nettoyage_Voo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cv5gNcavjvUsVeGgPIwvmj9gz60rTSKj
"""

import pandas as pd
import datetime
import pycountry

# --------------- Fonctions principales ------------------

def lire_fichiers(fichiers_streamlit):
    return [pd.read_csv(f, encoding="latin-1", sep=";") for f in fichiers_streamlit]

def verifier_uniques_id(*dfs):
    results = {}
    for i, df in enumerate(dfs):
        df_name = f"DataFrame_{i+1}"
        if 'Identifiant CNR' in df.columns:
            results[df_name] = df['Identifiant CNR'].is_unique
        else:
            results[df_name] = False
    return results

def garder_lignes_plus_completes(df, subset_cols):
    df['_nb_non_na'] = df.notna().sum(axis=1)
    df_sorted = df.sort_values(by=subset_cols + ['_nb_non_na'], ascending=[True]*len(subset_cols) + [False])
    df_cleaned = df_sorted.drop_duplicates(subset=subset_cols, keep='first').drop(columns=['_nb_non_na'])
    return df_cleaned

def concatener_bases_par_identifiant(*dfs):
    base_fusionnee = dfs[0]
    for df in dfs[1:]:
        base_fusionnee = pd.merge(base_fusionnee, df, on="Identifiant CNR", how="outer", suffixes=('', '_dup'))
    return base_fusionnee

def supprimer_colonnes_dup(df):
    cols_to_drop = [col for col in df.columns if col.endswith('_dup')]
    return df.drop(columns=cols_to_drop)

def garder_lignes_les_plus_completes_par_id(df, id_col='Identifiant CNR'):
    df['_nb_non_na'] = df.notna().sum(axis=1)
    df_sorted = df.sort_values(by=[id_col, '_nb_non_na'], ascending=[True, False])
    df_cleaned = df_sorted.drop_duplicates(subset=[id_col], keep='first').drop(columns=['_nb_non_na'])
    return df_cleaned

def convertir_colonnes_numeriques(df, colonnes):
    for col in colonnes:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
    return df

def executer_tous_les_tests(df):
    all_tests = {}
    all_tests.update(test_completude(df))
    all_tests.update(test_dates_coherentes(df))
    all_tests.update(test_coherence_logique(df))
    all_tests.update(test_validite_valeurs(df))
    all_tests.update(test_format(df))
    all_tests.update(test_dependances(df))
    all_tests['outliers_plaquettes'] = detecter_outliers(df, "Plaquettes", 150, 450)
    all_tests['outliers_hemoglobine'] = detecter_outliers(df, "Hb", 7, 20)
    all_tests.update(test_integrite_medicale(df))
    return all_tests

def generer_rapport_erreurs_excel(erreurs_dict, filename="rapport_erreurs_voo.xlsx"):
    with pd.ExcelWriter(filename) as writer:
        for nom_test, df_erreurs in erreurs_dict.items():
            if not df_erreurs.empty:
                sheet_name = nom_test[:31].replace(' ', '_')
                df_erreurs.to_excel(writer, sheet_name=sheet_name, index=False)
    return filename

# --------------- Fonctions de test (copiées depuis ton script) ------------------

# Toutes les fonctions test_completude, test_dates_coherentes, etc.
# doivent être reprises ici sans changement majeur (je peux les ajouter dans le fichier si tu veux)

# --------------- Fonction principale ------------------

def traiter_fichiers_utilisateur(fichiers_streamlit):
    dfs = lire_fichiers(fichiers_streamlit)

    # Nettoyage de chaque base avec complétude
    dfs_cleaned = [garder_lignes_plus_completes(df, ['Identifiant CNR']) for df in dfs]

    base = concatener_bases_par_identifiant(*dfs_cleaned)
    base = garder_lignes_les_plus_completes_par_id(base)
    base = supprimer_colonnes_dup(base)

    colonnes_numeriques = ["Parasitémie", "Créatininémie", "Score de galsgow", "Température",
                           "Hb", "Densité (%)", "Plaquettes", "Durée du séjour"]
    base = convertir_colonnes_numeriques(base, colonnes_numeriques)

    erreurs = executer_tous_les_tests(base)
    nom_rapport = generer_rapport_erreurs_excel(erreurs)

    return base, erreurs, nom_rapport